import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA

# 1. Sample Car Data (replace with your actual data loading)
data = {
    'Make': ['Toyota', 'Honda', 'Ford', 'BMW', 'Mercedes-Benz', 'Toyota', 'Honda', 'Ford', 'BMW', 'Mercedes-Benz'],
    'Model': ['Camry', 'Civic', 'F-150', 'X5', 'C-Class', 'RAV4', 'CR-V', 'Explorer', 'X3', 'E-Class'],
    'Body Style': ['Sedan', 'Sedan', 'Truck', 'SUV', 'Sedan', 'SUV', 'SUV', 'SUV', 'SUV', 'Sedan'],
    'Engine Type': ['Gasoline', 'Gasoline', 'Gasoline', 'Gasoline', 'Gasoline', 'Gasoline', 'Hybrid', 'Gasoline', 'Gasoline', 'Hybrid'],
    'Horsepower': [203, 158, 400, 335, 255, 203, 212, 300, 248, 362],
    'Fuel Efficiency (City)': [25, 32, 17, 21, 23, 27, 40, 18, 22, 28],
    'Price': [25000, 22000, 40000, 60000, 55000, 28000, 35000, 45000, 50000, 65000]
}
df = pd.DataFrame(data)

# 2. Feature Engineering (Optional but good practice)
df['Power/Weight Ratio'] = df['Horsepower'] / (df['Price'] / 1000) # Simplified weight proxy

# 3. Preprocessing
numerical_features = ['Horsepower', 'Fuel Efficiency (City)', 'Price', 'Power/Weight Ratio']
categorical_features = ['Make', 'Body Style', 'Engine Type']

# Create transformers for numerical and categorical features
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Create a column transformer to apply different transformations to different columns
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# 4. Clustering
# Apply preprocessing
processed_data = preprocessor.fit_transform(df)

# Determine the optimal number of clusters using the Elbow Method
inertia = []
range_n_clusters = range(2, 11)
for n_clusters in range_n_clusters:
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    kmeans.fit(processed_data)
    inertia.append(kmeans.inertia_)

plt.figure(figsize=(10, 6))
plt.plot(range_n_clusters, inertia, marker='o')
plt.title('Elbow Method for Optimal K')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.show()

# Based on the elbow plot (you'll need to visually inspect this), choose an optimal number of clusters
optimal_k = 3  # Example: Let's assume 3 is the elbow point

# Apply K-Means clustering with the chosen number of clusters
kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
df['Cluster'] = kmeans.fit_predict(processed_data)

# 5. Recommendation Function
def recommend_cars(df, car_name, n_recommendations=3):
    if car_name not in df['Model'].values:
        return "Car not found in the dataset."

    car_cluster = df[df['Model'] == car_name]['Cluster'].iloc[0]
    similar_cars = df[df['Cluster'] == car_cluster]
    if car_name in similar_cars['Model'].values:
        similar_cars = similar_cars[similar_cars['Model'] != car_name] # Exclude the input car

    if similar_cars.empty:
        return f"No similar cars found in the same cluster as {car_name}."

    return similar_cars.head(n_recommendations)

# 6. Example Usage and Output
example_car = 'Civic'
recommendations = recommend_cars(df.copy(), example_car)

print(f"\nRecommendations for '{example_car}':")
if isinstance(recommendations, pd.DataFrame):
    print(recommendations[['Make', 'Model', 'Body Style', 'Engine Type']])
else:
    print(recommendations)

# 7. Visualizing Clusters (using PCA for dimensionality reduction)
pca = PCA(n_components=2)
principal_components = pca.fit_transform(processed_data)
pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])
pca_df['Cluster'] = df['Cluster']
pca_df['Model'] = df['Model']

plt.figure(figsize=(10, 8))
sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=pca_df, palette='viridis', s=100)
for i, row in pca_df.iterrows():
    plt.annotate(row['Model'], (row['PC1'], row['PC2']), textcoords="offset points", xytext=(5,5), ha='left')
plt.title('Car Clusters Visualized (PCA)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()